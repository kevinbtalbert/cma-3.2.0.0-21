# Format is [CONFIGS-CMSERVICENAME]
# First specify the CM-CONFIG, if not present then BP config.
# if there are multiple default values then can be separated using pipe (|) Ex:dfs.blockreport.initialDelay


[CONFIGS-HDFS]
hadoop.http.cross-origin.max-age=1800
hadoop.http.cross-origin.allowed-headers=X-Requested-With,Content-Type,Accept,Origin,WWW-Authenticate,Accept-Encoding,Transfer-Encoding
hadoop.http.cross-origin.allowed-methods=GET,PUT,POST,OPTIONS,HEAD,DELETE
hadoop.http.cross-origin.allowed-origins=*

#hdfs-site
dfs.disk.balancer.enabled=true
dfs.heartbeat.interval=3
dfs.blockreport.initialDelay=120|120s|2m
dfs.block.access.token.enable=false
dfs.client.retry.policy.enabled=true
dfs.cluster.administrators=" hdfs"
dfs.content-summary.limit=5000
dfs.permissions.ContentSummary.subAccess=false
dfs_nfs3_dump_dir=/tmp/.hdfs-nfs
nfs.file.dump.dir=/tmp/.hdfs-nfs
nfs.udp.client.portmap.timeout.millis=5000
io_file_buffer_size= 131072
dfs.encrypt.data.transfer.cipher.suites=AES/CTR/NoPadding
dfs.block.access.token.enable=true

#core-site
io.file.buffer.size=4096
ha.failover-controller.active-standby-elector.zk.op.retries = 120
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization
hadoop.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer,org.apache.hadoop.security.HttpCrossOriginFilterInitializer|org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilterInitializer|org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilterInitializer,org.apache.hadoop.security.HttpCrossOriginFilterInitializer


#Ranger
xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.hdfs.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.hdfs.service.name={{repo_name}}
ranger.plugin.hdfs.policy.pollIntervalMs = 30000

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true

[CONFIGS-YARN]
yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
yarn.resourcemanager.work-preserving-recovery.enabled=true
yarn.webapp.ui2.enable=true
yarn.resourcemanager.webapp.cross-origin.enabled=true
yarn.webapp.api-service.enable=true
yarn.resourcemanager.placement-constraints.handler=scheduler
yarn.authorization-provider=org.apache.ranger.authorization.yarn.authorizer.RangerYarnAuthorizer
yarn.nodemanager.recovery.enabled=true
yarn.nodemanager.recovery.supervised=true
yarn.nodemanager.webapp.cross-origin.enabled=true
yarn.nodemanager.aux-services=mapreduce_shuffle,spark_shuffle
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.aux-services.spark_shuffle.class=org.apache.spark.network.yarn.YarnShuffleService
spark.authenticate=true
yarn.log-aggregation.file-controller.TFile.class=org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController

xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.yarn.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
ranger.plugin.yarn.policy.pollIntervalMs = 30000


xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true


[CONFIGS-HIVE_ON_TEZ]
hive.server2.webui.cors.allowed.headers=X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by
hiveserver2_enable_ldap_auth=NONE
hive.auto.convert.join.noconditionaltask=true
hive.merge.rcfile.block.level=true
hive.exec.max.dynamic.partitions.pernode=2000
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled=true
hive.mapjoin.hybridgrace.hashtable=false
hive.compactor.initiator.on=false
hive.exec.max.dynamic.partitions=5000
hive.compactor.worker.timeout=86400
hive.server2.thrift.http.path=cliservice
hive.enforce.sortmergebucketmapjoin=true
hive.mapjoin.bucket.cache.size=10000
hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider
hive.security.authorization.enabled=true
hive.server2.thrift.sasl.qop=auth
hive.merge.orcfile.stripe.level=true
hive.orc.splits.include.file.footer=false
hive.exec.compress.output=false
hive.user.install.directory=/user/
hive.prewarm.enabled=false
hive.compactor.delta.num.threshold=10
hive.orc.compute.splits.num.threads=10
metastore.create.as.acid=false
hive.optimize.bucketmapjoin=false
hive.exec.failure.hooks=org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook
hive.exec.compress.intermediate=false
hive.vectorized.execution.mapjoin.minmax.enabled=true
hive.exec.max.created.files=100000
hive.mapred.reduce.tasks.speculative.execution=false
hive.server2.tez.initialize.default.sessions=true
hive.stats.autogather=true
hive.mapjoin.optimized.hashtable=true
hive.vectorized.groupby.maxentries=1000000
hive.compactor.check.interval=300
hive.security.metastore.authorization.auth.reads=true
hive.compactor.delta.pct.threshold=0.1f
hive.stats.dbclass=fs
hive.exec.parallel=false
hive.query.results.cache.enabled=true
hive.exec.submitviachild=false
hive.strict.managed.tables=true
hive.map.aggr.hash.force.flush.memory.threshold=0.9
hive.merge.tezfiles=false
hive.exec.orc.split.strategy=HYBRID
hive.optimize.dynamic.partition.hashjoin=false
hive.convert.join.bucket.mapjoin.tez=false
hive.execution.engine=tez
hive.optimize.constant.propagation=true
hive.server2.max.start.attempts=5
hive.exec.dynamic.partition.mode=nonstrict
hive.exec.submit.local.task.via.child=true
hive.optimize.null.scan=true
hive.limit.optimize.enable=false
hive.cluster.delegation.token.store.zookeeper.znode=/hivedelegation
hive.server2.webui.enable.cors=true
hive.vectorized.execution.mapjoin.native.enabled=true
hive.materializedview.rewriting.incremental=false
hive.map.aggr.hash.min.reduction=0.5
hive.merge.nway.joins=false
hive.optimize.metadataonly=true
hive.prewarm.numcontainers=3
hive.exec.parallel.thread.number=8
hive.service.metrics.codahale.reporter.classes=org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter, org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter
hive.auto.convert.sortmerge.join.to.mapjoin=true
hive.fetch.task.aggr=false
hive.cli.print.header=false
hive.server2.table.type.mapping=CLASSIC
hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.auto.convert.sortmerge.join=true
hive.zookeeper.namespace=hive_zookeeper_namespace
hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator
hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory
hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook
hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook,org.apache.atlas.hive.hook.HiveHook
hive.server2.tez.default.queues=default
hive.security.authorization.enabled=true

xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.hive.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.hive.service.name={{repo_name}}
ranger.plugin.hive.policy.pollIntervalMs = 30000
ranger.plugin.hive.urlauth.filesystem.schemes = hdfs:,file:,wasb:,adl:
xasecure.hive.update.xapolicies.on.grant.revoke = true

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true

atlas.hook.hive.maxThreads = 5
atlas.hook.hive.keepAliveTime = 10
atlas.hook.hive.synchronous = false
atlas.hook.hive.minThreads = 5
atlas.hook.hive.numRetries = 3
atlas.hook.hive.queueSize = 1000



[CONFIGS-HIVE]
hiveserver2_enable_ldap_auth=NONE
hive.metastore.sasl.enabled=false
hive.auto.convert.join.noconditionaltask=true
hive.server2.allow.user.substitution=true
hive.merge.rcfile.block.level=true
hive.exec.max.dynamic.partitions.pernode=2000
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled=true
hive.mapjoin.hybridgrace.hashtable=false
hive.compactor.initiator.on=false
hive.exec.max.dynamic.partitions=5000
hive.compactor.worker.timeout=86400
hive.metastore.authorization.storage.checks=false
hive.server2.transport.mode=binary
hive.server2.thrift.http.path=cliservice
hive.enforce.sortmergebucketmapjoin=true
hive.mapjoin.bucket.cache.size=10000
hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider
hive.security.authorization.enabled=true
hive.server2.thrift.sasl.qop=auth
hive.merge.orcfile.stripe.level=true
hive.orc.splits.include.file.footer=false
hive.exec.compress.output=false
hive.user.install.directory=/user/
hive.prewarm.enabled=false
hive.compactor.delta.num.threshold=10
hive.orc.compute.splits.num.threads=10
metastore.create.as.acid=false
hive.optimize.bucketmapjoin=false
hive.exec.compress.intermediate=false
hive.vectorized.execution.mapjoin.minmax.enabled=true
hive.exec.max.created.files=100000
hive.mapred.reduce.tasks.speculative.execution=false
hive.server2.tez.initialize.default.sessions=true
hive.stats.autogather=true
hive.mapjoin.optimized.hashtable=true
hive.vectorized.groupby.maxentries=1000000
hive.compactor.check.interval=300
hive.security.metastore.authorization.auth.reads=true
hive.compactor.delta.pct.threshold=0.1f
javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver
hive.stats.dbclass=fs
hive.exec.parallel=false
hive.query.results.cache.enabled=true
hive.exec.submitviachild=false
hive.strict.managed.tables=true
hive.server2.authentication=NONE
hive.map.aggr.hash.force.flush.memory.threshold=0.9
hive.merge.tezfiles=false
hive.metastore.cache.pinobjtypes=Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order
hive.exec.orc.split.strategy=HYBRID
hive.optimize.dynamic.partition.hashjoin=false
hive.convert.join.bucket.mapjoin.tez=false
hive.execution.engine=tez
hive.optimize.constant.propagation=true
hive.server2.max.start.attempts=5
hive.exec.dynamic.partition.mode=nonstrict
hive.exec.submit.local.task.via.child=true
hive.optimize.null.scan=true
hive.limit.optimize.enable=false
hive.cluster.delegation.token.store.zookeeper.znode=/hivedelegation
hive.metastore.client.connect.retry.delay=1s
hive.vectorized.execution.mapjoin.native.enabled=true
hive.server2.thrift.http.port=10001
hive.materializedview.rewriting.incremental=false
hive.map.aggr.hash.min.reduction=0.5
hive.merge.nway.joins=false
hive.optimize.metadataonly=true
hive.prewarm.numcontainers=3
hive.exec.parallel.thread.number=8
hive.service.metrics.codahale.reporter.classes=org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter, org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter
hive.auto.convert.sortmerge.join.to.mapjoin=true
hive.fetch.task.aggr=false
hive.cli.print.header=false
hive.server2.table.type.mapping=CLASSIC
hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.server2.zookeeper.namespace=hiveserver2
hive.exec.dynamic.partition=true
hive.metastore.failure.retries=1
hive.auto.convert.sortmerge.join=true
hive.zookeeper.namespace=hive_zookeeper_namespace
hive.compactor.initiator.on=false
hive.compactor.worker.threads=5
hive.metastore.transactional.event.listeners=org.apache.hive.hcatalog.listener.DbNotificationListener

xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.hive.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.hive.service.name={{repo_name}}
ranger.plugin.hive.policy.pollIntervalMs = 30000
ranger.plugin.hive.urlauth.filesystem.schemes = hdfs:,file:,wasb:,adl:
xasecure.hive.update.xapolicies.on.grant.revoke = true

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true


[CONFIGS-TEZ]
tez.runtime.sorter.class=PIPELINED
tez.history.logging.service.class=org.apache.tez.dag.history.logging.proto.ProtoHistoryLoggingService

[CONFIGS-HBASE]
hbase.master.ui.readonly=false
hbase.zookeeper.useMulti=true
zookeeper.recovery.retry=30
hbase.master.wait.on.regionservers.timeout=4500
xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.hbase.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.hbase.service.name={{repo_name}}
ranger.plugin.hbase.policy.pollIntervalMs = 30000
hbase.master.namespace.init.timeou=1800000

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = true
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true
xasecure.hbase.update.xapolicies.on.grant.revoke = true

[CONFIGS-OOZIE]
oozie.service.AuthorizationService.authorization.enabled=false
oozie.systemmode=NORMAL
oozie.service.JPAService.pool.max.active.conn=10
use.system.libpath.for.mapreduce.and.pig.jobs=false
oozie.service.PurgeService.purge.interval=3600
oozie.authentication.simple.anonymous.allowed=true


[CONFIGS-SQOOP_CLIENT]

[CONFIGS-SPARK_ON_YARN]
spark.history.provider=org.apache.spark.deploy.history.FsHistoryProvider
spark.history.kerberos.enabled=false
spark.history.ui.acls.enable=false
spark.sql.orc.impl=native
spark.sql.statistics.fallBackToHdfs=false
spark.shuffle.unsafe.file.output.buffer=32k # m - tool has to convert and then validate
spark.yarn.queue=default
spark.acls.enable=false
spark.sql.hive.convertMetastoreOrc=true
spark.sql.orc.filterPushdown=true
spark.io.compression.lz4.blockSize=32k  // kb - tool has to convert and then validate
spark.sql.autoBroadcastJoinThreshold=10485760
spark.shuffle.file.buffer=32k  // m - tool has to convert and then validate

xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.spark.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
ranger.plugin.spark.policy.pollIntervalMs = 30000

[CONFIGS-LIVY]
livy.spark.master=yarn-cluster
livy.server.session.timeout=3600000
livy.environment=production
livy.repl.enableHiveContext=true

[CONFIGS-KAFKA]
xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.kafka.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.kafka.service.name={{repo_name}}
ranger.plugin.kafka.policy.pollIntervalMs = 30000

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = true
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true

[CONFIGS-RANGER]
xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.ranger.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.ldap.user.dnpattern=uid={0},ou=users,dc=xasecure,dc=net
xasecure.audit.jaas.Client.loginModuleControlFlag=required
xasecure.audit.jaas.Client.option.useKeyTab=true
xasecure.audit.jaas.Client.option.storeKey=false
xasecure.audit.jaas.Client.option.serviceName=solr

ranger.ldap.ad.url={{ranger_ug_ldap_url}}
ranger.unixauth.service.hostname={{ugsync_host}}
ranger.ldap.base.dn=dc=example,dc=com
ranger.ldap.ad.base.dn=dc=example,dc=com
ranger.usersync.ldap.searchBase=dc=hadoop,dc=apache,dc=org

ranger.ldap.ad.bind.dn= {{ranger_ug_ldap_bind_dn}}
ranger.ldap.group.searchfilter={{ranger_ug_ldap_group_searchfilter}}
ranger.ldap.group.searchbase={{ranger_ug_ldap_group_searchbase}}
ranger.ldap.bind.dn = {{ranger_ug_ldap_bind_dn}}



ranger.kms.service.user.hive = hive
ranger.plugins.hive.serviceuser = hive
ranger.plugins.kms.serviceuser = kms
ranger.kms.service.user.hdfs = hdfs
ranger.plugins.yarn.serviceuser = yarn
ranger.plugins.hbase.serviceuser = hbase
ranger.plugins.hdfs.serviceuser = hdfs
ranger.plugins.atlas.serviceuser = atlas
ranger.plugins.knox.serviceuser = knox
ranger.plugins.kafka.serviceuser = kafka

ranger.usersync.ldap.bindalias = testldapalias
ranger.usersync.sink.impl.class = org.apache.ranger.unixusersync.process.PolicyMgrUserGroupBuilder
ranger.usersync.policymgr.alias = ranger.usersync.policymgr.password
ranger.usersync.unix.group.file = /etc/group
ranger.usersync.unix.password.file = /etc/passwd
ranger.usersync.policymanager.mockrun = false
ranger.usersync.passwordvalidator.path  =  ./native/credValidator.uexe


# Ranger Tagsync
atlas.kafka.security.protocol  =  SASL_PLAINTEXT
atlas.authentication.method.kerberos  =  true
atlas.jaas.KafkaClient.option.useKeyTab  =  true
atlas.jaas.KafkaClient.loginModuleName  =  com.sun.security.auth.module.Krb5LoginModule
atlas.jaas.KafkaClient.option.serviceName  =  kafka
atlas.jaas.KafkaClient.option.storeKey  =  true
atlas.jaas.KafkaClient.loginModuleControlFlag  =  required
atlas.kafka.sasl.kerberos.service.name  =  kafka


[CONFIGS-RANGER_KMS]
xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.hdfs.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.kms.service.name={{repo_name}}
ranger.plugin.kms.policy.pollIntervalMs = 30000

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true

ranger.contextName  =  /kms
ranger.service.shutdown.port  =  7085
ranger.service.https.attrib.clientAuth  =  want
ranger.service.https.attrib.client.auth  =  want
ajp.enabled  =  false


[CONFIGS-ATLAS]
xasecure.audit.jaas.Client.loginModuleName=com.sun.security.auth.module.Krb5LoginModule
ranger.plugin.atlas.policy.source.impl=org.apache.ranger.admin.client.RangerAdminRESTClient
#ranger.plugin.atlas.service.name={{repo_name}}
ranger.plugin.atlas.policy.pollIntervalMs = 30000

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true

atlas.kafka.sasl.kerberos.service.name = kafka
atlas.jaas.KafkaClient.option.serviceName =  kafka


[CONFIGS-KNOX]
#ranger.plugin.knox.service.name={{repo_name}}||{{repo_name}}
ranger.plugin.knox.policy.source.impl=org.apache.ranger.admin.client.RangerAdminJersey2RESTClient
ranger.plugin.knox.policy.pollIntervalMs = 30000

xasecure.audit.destination.hdfs = true
xasecure.audit.jaas.Client.loginModuleControlFlag = required
xasecure.audit.jaas.Client.option.serviceName= solr
xasecure.audit.jaas.Client.option.useKeyTab = true
xasecure.audit.destination.solr.force.use.inmemory.jaas.config = true
xasecure.audit.destination.solr = true
xasecure.audit.provider.summary.enabled = false
xasecure.audit.jaas.Client.option.storeKey = false
xasecure.audit.is.enabled=true


[CONFIGS-NIFI]
nifi.web.http.port = {{nifi_node_port}}
nifi.authorizer.configuration.file = {{nifi_config_dir}}/authorizers.xml
nifi.login.identity.provider.configuration.file = {{nifi_config_dir}}/login-identity-providers.xml
nifi.state.management.configuration.file = {{nifi_config_dir}}/state-management.xml
nifi.cluster.flow.election.max.candidates = {{nifi_num_nodes}}
nifi.cluster.node.address = {{nifi_node_host}}
nifi.cluster.node.protocol.port = {{nifi_node_protocol_port}}
nifi.database.directory = {{nifi_database_dir}}
nifi.documentation.working.directory = {{nifi_internal_dir}}/work/docs/components
nifi.flow.configuration.archive.dir = {{nifi_internal_dir}}/archive/
nifi.nar.library.autoload.directory = {{nifi_internal_dir}}/work/extensions
nifi.nar.working.directory = {{nifi_internal_dir}}/work/nar
nifi.templates.directory = {{nifi_internal_dir}}/templates
nifi.web.jetty.working.directory = {{nifi_internal_dir}}/work/jetty
nifi.flow.configuration.file = {{nifi_flow_config_dir}}/flow.xml.gz
nifi.flowfile.repository.directory = {{nifi_flowfile_repo_dir}}
nifi.nar.library.directory = {{nifi_install_dir}}/lib
nifi.web.war.directory = {{nifi_install_dir}}/lib
nifi.provenance.repository.directory.default = {{nifi_provenance_repo_dir_default}}
nifi.security.user.authorizer = {{nifi_authorizer}}
nifi.zookeeper.connect.string = {{zookeeper_quorum}}
nifi.zookeeper.root.node = {{nifi_znode}}
nifi.web.https.port = {{nifi_node_ssl_port}}
nifi.sensitive.props.key = {{nifi_sensitive_props_key}}
nifi.content.repository.directory.default = {{nifi_content_repo_dir_default}}
nifi.web.http.host = {{nifi_node_nonssl_host}}


[CONFIGS-NIFIREGISTRY]
nifi.registry.db.directory = {{nifi_registry_database_dir}}
nifi.registry.extension.dir.ranger = {{nifi_registry_install_dir}}/ext/ranger/lib
nifi.registry.providers.configuration.file = {{nifi_registry_config_dir}}/providers.xml
nifi.registry.security.authorizers.configuration.file = {{nifi_registry_config_dir}}/authorizers.xml
nifi.registry.security.identity.providers.configuration.file = {{nifi_registry_config_dir}}/identity-providers.xml
nifi.registry.web.jetty.working.directory = {{nifi_registry_internal_dir}}/work/jetty
nifi.registry.web.war.directory = {{nifi_registry_install_dir}}/lib
nifi.registry.web.http.port = {{nifi_registry_port}}
nifi.registry.security.authorizer = {{nifi_registry_authorizer}}
nifi.registry.security.needClientAuth = {{nifi_registry_needClientAuth}}
nifi.registry.web.https.port = {{nifi_registry_ssl_port}}
nifi.registry.web.http.host = {{nifi_registry_nonssl_host}}
