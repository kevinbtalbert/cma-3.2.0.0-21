<?xml version="1.0"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->

<upgrade-config-changes xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="upgrade-config.xsd">
  <services>
    <service name="RANGER_KMS">
      <component name="RANGER_KMS_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_3_1_ranger_kms_keysecure_configuration" summary="Updating dbks-site configurations for Ranger KMS Keysecure support">
            <type>dbks-site</type>
            <set key="ranger.kms.keysecure.enabled" value="false" if-type="dbks-site" if-key="ranger.kms.keysecure.enabled" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.UserPassword.Authentication" value="true" if-type="dbks-site" if-key="ranger.kms.keysecure.UserPassword.Authentication" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.masterkey.name" value="" if-type="dbks-site" if-key="ranger.kms.keysecure.masterkey.name" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.login.username" value="" if-type="dbks-site" if-key="ranger.kms.keysecure.login.username" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.login.password" value="" if-type="dbks-site" if-key="ranger.kms.keysecure.login.password" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.login.password.alias" value="ranger.ks.login.password" if-type="dbks-site" if-key="ranger.kms.keysecure.login.password.alias" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.hostname" value="" if-type="dbks-site" if-key="ranger.kms.keysecure.hostname" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.masterkey.size" value="256" if-type="dbks-site" if-key="ranger.kms.keysecure.masterkey.size" if-key-state="absent"/>
            <set key="ranger.kms.keysecure.sunpkcs11.cfg.filepath" value="" if-type="dbks-site" if-key="ranger.kms.keysecure.sunpkcs11.cfg.filepath" if-key-state="absent"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="RANGER">
      <component name="RANGER_ADMIN">
        <changes>
          <definition xsi:type="configure" id="hdp_3_1_maint_ranger_audit_solr_bootstrap" summary="Disabling Ranger Audit Solr Bootstrap Configuration">
            <type>ranger-admin-site</type>
            <set key="ranger.audit.solr.bootstrap.enabled" value="false" if-type="ranger-admin-site" if-key="ranger.audit.solr.bootstrap.enabled" if-key-state="absent"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="KAFKA">
      <component name="KAFKA_BROKER">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_kafka_kerberos_patch">
            <type>kafka-env</type>
            <replace key="content" find="KAFKA_KERBEROS_PARAMS" replace-with="KAFKA_OPTS"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="OOZIE">
      <component name="OOZIE_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_update_oozie_env_template_config">
            <type>oozie-env</type>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='unset OOZIE_CONFIG'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='unset CATALINA_BASE'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='unset CATALINA_TMPDIR'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='unset OOZIE_CATALINA_HOME'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='unset CATALINA_OPTS'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='export JETTY_PID_FILE="$CATALINA_PID"'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='unset CATALINA_PID'/>
            <insert key="content" insert-type="append" newline-before="true" newline-after="true" value='export OOZIE_CONFIG={{conf_dir}}'/>
          </definition>
          <definition xsi:type="configure" id="hdp_7_1_update_oozie_hadoop_accessor_service_config">
            <type>oozie-site</type>
            <set key="oozie.service.HadoopAccessorService.hadoop.configurations" value="*={{conf_dir}}/hadoop-conf" />
          </definition>
          <definition xsi:type="configure" id="hdp_7_1_update_oozie_credentials_credentialclasses_config">
            <type>oozie-site</type>
            <replace key="oozie.credentials.credentialclasses" find="HiveCredentials" replace-with="HCatCredentials" />
          </definition>
        </changes>
      </component>
    </service>

    <service name="SPARK2">
      <component name="SPARK2_CLIENT">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_0_0_spark2_env">
            <type>spark2-env</type>
            <insert key="content" insert-type="append" newline-before="true" newline-after="false"
                    value="# Add Hadoop lzo jar to the classpath (if found)
                      &#10;if [ -z &quot;${HADOOP_VERSION}&quot; ]; then
                      &#10; if [ `command -v hdp-select` ]; then
                      &#10;   HADOOP_VERSION=`hdp-select status | grep hadoop-client | awk -F &quot; &quot; &apos;{print $3}&apos;`
                      &#10; else
                      &#10;   echo -e &quot;command hdp-select is not found, please manually set HADOOP_VERSION in spark-env.sh or current environment&quot; 1>&amp;2
                      &#10;   exit 1
                      &#10; fi
                      &#10;fi
                      &#10;
                      &#10;HADOOP_LZO_JAR=
                      &#10;HADOOP_LZO_DIR=&quot;/usr/hdp/${HADOOP_VERSION}/hadoop/lib&quot;
                      &#10;num_jars=&quot;$(ls -1 &quot;$HADOOP_LZO_DIR&quot; | grep &quot;^hadoop-lzo.*${HADOOP_VERSION}\.jar$&quot; | wc -l)&quot;
                      &#10;if [ &quot;$num_jars&quot; -eq &quot;0&quot; -a -z &quot;$HADOOP_LZO_JAR&quot; ]; then
                      &#10; HADOOP_LZO_JAR=
                      &#10;elif [ &quot;$num_jars&quot; -gt &quot;1&quot; ]; then
                      &#10; echo &quot;Found multiple Hadoop lzo jars in $HADOOP_LZO_DIR:&quot; 1>&amp;2
                      &#10; echo &quot;Please remove all but one jar.&quot; 1>&amp;2
                      &#10; exit 1
                      &#10;elif [ &quot;$num_jars&quot; -eq &quot;1&quot; ]; then
                      &#10; LZO_JARS=&quot;$(ls -1 &quot;$HADOOP_LZO_DIR&quot; | grep &quot;^hadoop-lzo-.*${HADOOP_VERSION}\.jar$&quot; || true)&quot;
                      &#10; HADOOP_LZO_JAR=&quot;${HADOOP_LZO_DIR}/${LZO_JARS}&quot;
                      &#10;fi
                      &#10;
                      &#10;export SPARK_DIST_CLASSPATH=${SPARK_DIST_CLASSPATH}:${HADOOP_LZO_JAR}"/>
          </definition>
          <definition xsi:type="configure" id="hdp_7_1_0_0_remove_hive_metastore">
            <type>spark2-defaults</type>
            <transfer operation="delete" delete-key="spark.sql.hive.metastore.version" />
            <transfer operation="delete" delete-key="spark.sql.hive.metastore.jars" />
          </definition>
        </changes>
      </component>
    </service>

    <service name="HIVE">
      <component name="HIVE_METASTORE">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_disable_hive_metastore_strict_check" summary="Disable metastore strict table location check">
            <type>hivemetastore-site</type>
            <set key="metastore.strict.table.location.check" value="false"/>
          </definition>
          <definition xsi:type="configure" id="hdp_7_1_change_drfa_log_appender" summary="Update HIVE log appender type">
            <type>hive-log4j2</type>
            <replace key="content" find="RollingFile" replace-with="RollingRandomAccessFile" if-key="content" if-key-state="present"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="DRUID">
      <component name="DRUID_OVERLORD">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_0_0_druid_common">
            <type>druid-common</type>
            <replace key="druid.monitoring.monitors" find="io.druid.java.util.metrics.JvmMonitor"
            replace-with="org.apache.druid.java.util.metrics.JvmMonitor"/>
            <regex-replace key="druid.extensions.loadList" find="([, ]*)&quot;druid-kafka-eight&quot;" replace-with=""/>
            <regex-replace key="druid.extensions.loadList" find="&quot;druid-kafka-eight&quot;([, ]*)" replace-with=""/>
          </definition>

          <definition xsi:type="configure" id="hdp_7_1_0_0_druid_env">
            <type>druid-env</type>
            <replace key="druid.broker.jvm.opts" find="io.druid.common.config.Log4jShutdown"
            replace-with="org.apache.druid.common.config.Log4jShutdown"/>

            <replace key="druid.coordinator.jvm.opts" find="io.druid.common.config.Log4jShutdown"
            replace-with="org.apache.druid.common.config.Log4jShutdown"/>

            <replace key="druid.middlemanager.jvm.opts" find="io.druid.common.config.Log4jShutdown"
            replace-with="org.apache.druid.common.config.Log4jShutdown"/>

            <replace key="druid.historical.jvm.opts" find="io.druid.common.config.Log4jShutdown"
            replace-with="org.apache.druid.common.config.Log4jShutdown"/>

            <replace key="druid.overlord.jvm.opts" find="io.druid.common.config.Log4jShutdown"
            replace-with="org.apache.druid.common.config.Log4jShutdown"/>

            <replace key="druid.router.jvm.opts" find="io.druid.common.config.Log4jShutdown"
            replace-with="org.apache.druid.common.config.Log4jShutdown"/>
          </definition>

          <definition xsi:type="configure" id="hdp_7_1_0_0_druid_log4j">
            <type>druid-log4j</type>
            <replace key="content" find="io.druid"
            replace-with="org.apache.druid"/>
          </definition>

          <definition xsi:type="configure" id="hdp_7_1_0_0_druid_router">
            <type>druid-router</type>
            <set key="druid.router.managementProxy.enabled" value="true"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="TEZ">
      <component name="TEZ_CLIENT">
        <changes>
          <definition xsi:type="configure" id="hdp_3_x_tez_native_path_update">
            <type>tez-site</type>
            <replace key="tez.am.launch.env"
                     find="/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-{{architecture}}-64"
                     replace-with="/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-{{architecture}}-64"/>
            <replace key="tez.task.launch.env"
                     find="/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-{{architecture}}-64"
                     replace-with="/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-{{architecture}}-64"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="MAPREDUCE2">
      <component name="MAPREDUCE2_CLIENT">
        <changes>
          <definition xsi:type="configure" id="hdp_3_x_mapreduce_native_path_update">
            <type>mapred-site</type>
            <replace key="mapreduce.admin.user.env"
                     find="/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-{{architecture}}-64"
                     replace-with="/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-{{architecture}}-64"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="KNOX">
      <component name="KNOX_GATEWAY">
        <changes>
          <definition xsi:type="configure" id="hdp_7_x_enable_ranger_knox_sso">
            <type>gateway-site</type>
            <set key="gateway.incoming.xforwarded.enabled" value="false" if-type="gateway-site" if-key="gateway.incoming.xforwarded.enabled" if-key-state="absent"/>
          </definition>
          <definition xsi:type="configure" id="hdp_7_x_knox_topology_fix_hive_schema">
            <type>topology</type>
            <replace key="content"
                     find="&lt;url&gt;http://{{hive_server_host}}:{{hive_http_port}}/{{hive_http_path}}&lt;/url&gt;"
                     replace-with="&lt;url&gt;{{hive_scheme}}://{{hive_server_host}}:{{hive_http_port}}/{{hive_http_path}}&lt;/url&gt;"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="ATLAS">
      <component name="ATLAS_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_6_maint_jaas_config_for_atlas" summary="Updating atlas jaas application properties">
            <type>application-properties</type>
            <set key ="atlas.jaas.ticketBased-KafkaClient.loginModuleControlFlag" value="required"
                 if-type="cluster-env" if-key="security_enabled" if-value="true"/>
            <set key ="atlas.jaas.ticketBased-KafkaClient.loginModuleName" value="com.sun.security.auth.module.Krb5LoginModule"
                 if-type="cluster-env" if-key="security_enabled" if-value="true"/>
            <set key ="atlas.jaas.ticketBased-KafkaClient.option.useTicketCache" value="true"
                 if-type="cluster-env" if-key="security_enabled" if-value="true"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="HBASE">
      <component name="HBASE_MASTER">
        <changes>
          <definition xsi:type="configure" id="hdp_7_1_7_setup_hbase_master_procedure_store_drain" summary="Setup HBase for Master Procedure Store drain">
            <type>hbase-site</type>
            <set key ="hbase.procedure.upgrade-to-2-2" value="true" if-type="hbase-site" if-key="hbase.procedure.upgrade-to-2-2" if-key-state="absent"/>
          </definition>
          <definition xsi:type="configure" id="hdp_7_1_7_complete_hbase_master_procedure_store_drain" summary="Complete HBase for Master Procedure Store drain">
            <type>hbase-site</type>
            <transfer operation="delete" delete-key="hbase.procedure.upgrade-to-2-2" />
          </definition>
        </changes>
      </component>
    </service>
  </services>
</upgrade-config-changes>